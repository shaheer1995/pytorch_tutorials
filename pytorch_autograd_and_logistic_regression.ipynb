{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_autograd_and_logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdJ1mi5xIV7j"
      },
      "source": [
        "Autograd Introduction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfblnCyNGB3f"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJS1pvxZGRfa",
        "outputId": "ec7b8e08-42ef-4bc1-c27e-c47e38e59952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.rand(3, requires_grad = True)\n",
        "print(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1884, 0.7729, 0.3795], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4umSDEiGYdo",
        "outputId": "a2cc606f-d71d-4016-f0f8-dc0774d2cf77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = x+2\n",
        "print(y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.1884, 2.7729, 2.3795], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWYsHzQ6A_WF",
        "outputId": "2a16c63f-eaed-4d4a-f3ea-cfd43e1ca278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "z = y*y*2\n",
        "print(z)\n",
        "\n",
        "z = z.mean()\n",
        "print(z)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 9.5783, 15.3780, 11.3239], grad_fn=<MulBackward0>)\n",
            "tensor(12.0934, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-qWSZUlBq44",
        "outputId": "3bb1b8e6-c53c-47f1-83a5-f96416fb830c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.9179, 3.6972, 3.1726])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNwGCrjsCTJo",
        "outputId": "6739d4c8-2b3e-4265-9cca-ac9c6e525fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " #prevent tracking gradients\n",
        " # 3 options\n",
        " \n",
        "# x.requires_grad_(False)\n",
        "# print(x)\n",
        "\n",
        "# y = x.detach()\n",
        "# print(y)\n",
        "\n",
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "  print(y)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.1884, 2.7729, 2.3795])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQTdPv3gVvm_"
      },
      "source": [
        "Basic steps of a neural networks\n",
        "1.   Forward Pass\n",
        "2.   Compute Local Gradient\n",
        "3.   Backward Pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xxlf44_E7iO",
        "outputId": "4bf9d483-1391-4e28-cbd2-b1da2a423436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "#Forward Pass and compute loss\n",
        "y_hat = w*x\n",
        "loss = (y_hat - y)**2\n",
        "\n",
        "print(loss)\n",
        "\n",
        "#Backward Pass\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(w.grad)\n",
        "\n",
        "## Update weight and continue\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftqpyciJI19n"
      },
      "source": [
        "Implementing Linear Regression without Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhFjUDTz_BpA",
        "outputId": "15fb91ce-1421-4734-c1ba-a490bf0c6f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#f=2*x\n",
        "\n",
        "X = np.array([1,2,3,4],dtype=np.float32)\n",
        "Y = np.array([2,4,6,8],dtype=np.float32)\n",
        "\n",
        "w = 0\n",
        "\n",
        "#model prediction\n",
        "def forward(x):\n",
        "  return w*x\n",
        "\n",
        "#loss = MSE\n",
        "def loss(y,y_pred):\n",
        "  return ((y_pred-y)**2).mean()\n",
        "\n",
        "#gradient\n",
        "#MSE = 1/N * (w*x-y)**2\n",
        "#dJ/dw = 1/N 2x - y\n",
        "\n",
        "def gradient(x,y,y_pred):\n",
        "  return np.dot(2*x, y_pred-y).mean()\n",
        "\n",
        "\n",
        "print(f'Prediction before training : f(5) = {forward(5):.3f} ')\n",
        "\n",
        "#Training\n",
        "learning_rate = 0.01\n",
        "n_itr = 20\n",
        "\n",
        "for epoch in range(n_itr):\n",
        "  #forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  #compute loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradients\n",
        "  dw = gradient(X,Y,y_pred)\n",
        "\n",
        "  #update weights\n",
        "  w -=(learning_rate * dw)\n",
        "\n",
        "  if epoch%2 == 0:\n",
        "    print(f'epoch : {epoch+1} : w = {w: .3f}, loss = {l: .3f} ')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {forward(5):.3f} ')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction before training : f(5) = 0.000 \n",
            "epoch : 1 : w =  1.200, loss =  30.000 \n",
            "epoch : 3 : w =  1.872, loss =  0.768 \n",
            "epoch : 5 : w =  1.980, loss =  0.020 \n",
            "epoch : 7 : w =  1.997, loss =  0.001 \n",
            "epoch : 9 : w =  1.999, loss =  0.000 \n",
            "epoch : 11 : w =  2.000, loss =  0.000 \n",
            "epoch : 13 : w =  2.000, loss =  0.000 \n",
            "epoch : 15 : w =  2.000, loss =  0.000 \n",
            "epoch : 17 : w =  2.000, loss =  0.000 \n",
            "epoch : 19 : w =  2.000, loss =  0.000 \n",
            "Prediction after training : f(5) = 10.000 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcLiNe0xXCzb"
      },
      "source": [
        "Using Autograd\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V026L6go_pPU",
        "outputId": "4df139d2-12fe-4823-d214-0c1ea67cb92a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "# 1) Design the model (input,output,forward pass)\n",
        "# 2) Construct the loss and optimizer\n",
        "# 3) Training Loop  \n",
        "#    *forward pass : compute predction\n",
        "#    *backward pass : gradients\n",
        "#    *update weights\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
        "\n",
        "x_test = torch.tensor([5],dtype=torch.float32)\n",
        "n_samples,n_features = X.shape\n",
        "print(n_samples,n_features)\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "model = nn.Linear(input_size,output_size)\n",
        "\n",
        "print(f'Prediction before training : f(5) = {model(x_test).item():.3f} ')\n",
        "\n",
        "#Training\n",
        "learning_rate = 0.05\n",
        "n_itr = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_itr):\n",
        "  #forward pass\n",
        "  y_pred = model(X)\n",
        "\n",
        "  #compute loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  #gradients = backward pass\n",
        "  l.backward() #dl/dw\n",
        "  \n",
        "\n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%10 == 0:\n",
        "    [w,b] = model.parameters()\n",
        "    print(f'epoch : {epoch+1} : w = {w[0][0].item(): .3f}, loss = {l: .3f} ')\n",
        "\n",
        "print(f'Prediction after training : f(5) = {model(x_test).item():.3f} ')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 1\n",
            "Prediction before training : f(5) = 5.118 \n",
            "epoch : 1 : w =  1.658, loss =  6.545 \n",
            "epoch : 11 : w =  1.824, loss =  0.046 \n",
            "epoch : 21 : w =  1.849, loss =  0.034 \n",
            "epoch : 31 : w =  1.870, loss =  0.025 \n",
            "epoch : 41 : w =  1.888, loss =  0.019 \n",
            "epoch : 51 : w =  1.904, loss =  0.014 \n",
            "epoch : 61 : w =  1.917, loss =  0.010 \n",
            "epoch : 71 : w =  1.929, loss =  0.008 \n",
            "epoch : 81 : w =  1.939, loss =  0.006 \n",
            "epoch : 91 : w =  1.947, loss =  0.004 \n",
            "Prediction after training : f(5) = 9.905 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lx1YVb8nYsJ"
      },
      "source": [
        "Linear Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISxXcgTXQd5O",
        "outputId": "a1cd1474-9d41-4e48-859a-5aec9737da5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_numpy, Y_numpy = datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=1)  \n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "Y = torch.from_numpy(Y_numpy.astype(np.float32))\n",
        "\n",
        "Y = Y.view(Y.shape[0],1)\n",
        "\n",
        "n_samples,n_features = X.shape\n",
        "\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model =  nn.Linear(input_size,output_size)\n",
        "\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  y_pred = model(X)\n",
        "  loss = criterion(y_pred,Y)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1)%10 == 0:\n",
        "    print(f'epoch {epoch+1}, loss = {loss.item():.3f}')\n",
        "\n",
        "#plot\n",
        "predicted = model(X).detach().numpy()\n",
        "plt.plot(X_numpy,Y_numpy,'ro')\n",
        "plt.plot(X_numpy,predicted,'b')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 10, loss = 4383.021\n",
            "epoch 20, loss = 3271.298\n",
            "epoch 30, loss = 2466.546\n",
            "epoch 40, loss = 1883.402\n",
            "epoch 50, loss = 1460.436\n",
            "epoch 60, loss = 1153.379\n",
            "epoch 70, loss = 930.285\n",
            "epoch 80, loss = 768.073\n",
            "epoch 90, loss = 650.047\n",
            "epoch 100, loss = 564.117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5BcZZ3v8fc3iZNizKpkEgWBzESNlwLWxcsUuIouIsqP/RF1UYMTQFjNDYjrr1sIRsvVurOrskKhCBgxgmQAWbku2RJBwrLiliAMGiHIRQbIhGSzMJmIKAECyff+cU5nTnef0z9P9+nu83lVdc3Mc06fftIF3376Od/n+5i7IyIi+TIr6w6IiEj7KfiLiOSQgr+ISA4p+IuI5JCCv4hIDs3JugO1WrBggQ8NDWXdDRGRrnHvvfdud/eFcce6JvgPDQ0xPj6edTdERLqGmU0mHdO0j4hIDin4i4jkkIK/iEgOKfiLiOSQgr+ISA4p+IuIlBobg6EhmDUr+Dk2lnWPUqfgLyISNTYGK1bA5CS4Bz9XrGj/B0CLP4AU/EVEolatgp07i9t27gza26UNH0AK/iIiUZs319feCm34AFLwFxGJWrSovvZWaMMHkIK/iEjU6Cj09xe39fcH7e3Shg8gBX8RkaiREVi9GgYHwSz4uXp10N4ubfgA6prCbiIibTMy0t5gH/f6EMzxb94cjPhHR1Ptk0b+IiJZSkrpHBmBTZtgz57gZ8ofRhr5i4hkpZDSWcjsKaR0Qsu/eWjkLyKSlQzXFCj4i4hkJcM1BQr+IiJZyXBNgYK/iEhWMlxToOAvIpKVDNcUKNtHRCRLGa0pSGXkb2ZrzOxJM9sYafsHM9tqZhvCx0mRY+eb2YSZPWRmx6fRBxGRhlQrndyjtf3TGvlfCVwCfK+k/SJ3/+dog5kdAiwDDgVeDaw3s9e7++6U+iIiUptqefYZ5uG3Wiojf3e/A9hR4+lLgevc/Xl3fwyYAI5Mox8iInWplmffCbX9W6TVN3zPMbP7wmmhfcO2A4DHI+dsCdvKmNkKMxs3s/GpqakWd1VEelbS1E21PPsM8/AnJmDOHPjiF1tz/VYG/8uA1wKHA9uAr9V7AXdf7e7D7j68cOHCtPsnInlQaVesann2GeThT0wEiT9LlsDu3fDDH7bmdVoW/N39CXff7e57gG8zM7WzFTgocuqBYZuISPoqTd1Uy7NvYx7+I4/MBP2Ca6+FDRtSfymghcHfzPaP/PkeoJAJtA5YZmZzzWwxsAS4u1X9EJGcqzR1Uy3Pvg15+LfdFlz6da+baRsbC76kLFuW2suUMXdv/iJm1wLHAAuAJ4AvhH8fDjiwCfhf7r4tPH8VcCbwIvAJd/9xtdcYHh728fHxpvsqIjkzNBRM9ZQaHAxKJWfk9tvh2GOL2773PTj11PRew8zudffhuGOppHq6+ykxzd+pcP4o0MY90UQkt0ZHi9M1of3bMkb89KdwzDHFbccfDzff3N5+qLyDiPS2TtiWEbjjjuDlo4H/uOOC6Z12B35Q8BeRPKhlV6wWreT9z/8Mgv5f/MVM29vfHgT9W29N5SUaoto+IiItWMn785/DW95S3PbWtwbfADqBRv4iIimu5L3rrmCkHw38b35zMNLvlMAPGvmLiKSykvfuu+Goo4rbjjoq+DDoRBr5i4g0sZL3nnuCkX408B9xRDDS79TADwr+ItKMXil33MBK3nvvDYL+kZGylIcfHgT9bliSpOAvIo2pVDOn29SRDvrLXwanDEeWTr3hDcFb8KtftbHPTUplhW87aIWvSAcYGwtugm7eHIz2d8dsw5HxytlW2bAB3vjG4rZDD4WNG+PP7wSVVvhq5C8itSkd6ccFfki33HEHTCv95CfBSD8a+A8+OHgLOjnwV6NsHxGpTVw6ZJy0yh1nvIvW+vXwzncWt73udfDwwy1/6bbQyF9EalPLiD7NmjkZ7aL1/e8HI/3SwO/eO4EfFPxFpFZJI/rZs1tTM6fNu2hdfnnwzygto+wePHqNgr+I1CYpHfKqqyrXzGlUm3bR+qd/CoL+WWcVt/dq0C9Q8BeR2rS7OmaLd9H66leDf8ZnP1vc3utBv0DBX0RqV0t1zDRfq9EPmwpZQhdeGFzuM58pfkpegn6B8vxFpLeUZgkB9Pfz9b/9KR+/ujzlvUtCYENanudvZmvM7Ekz2xhpm29mt5rZw+HPfcN2M7Ovm9mEmd1nZv8zjT6ISMrakWPfitcoyRL6R87Hdj5TFvjzNtIvlda0z5XACSVt5wG3ufsS4Lbwb4ATCTZtXwKsAC5LqQ8ikpZ2lG6Ie41TT4Wzz27uumE20Fc4F8NZxT8WHc570C9IJfi7+x3AjpLmpcBV4e9XAe+OtH/PA3cBrzCz/dPoh4ikpB059nGv4R7kXDbxIXPhK76I4ZzHV4ovPTikoB/Ryhu+r3L3beHv/w28Kvz9AODxyHlbwrYyZrbCzMbNbHxqaqp1PRWRYu3IsU+6ljssX173NNA3vhHcyP307z5ffDkM739pZhu2d6q2ZPt4cFe57s9cd1/t7sPuPrxw4cIW9ExEYrUjx77atWqcarrssiDo//3fF7f74BBuszLbsL3TtTL4P1GYzgl/Phm2bwUOipx3YNgmIp2ixTn2e1/DrPI5FaaarrgieHrpLYI9e8I5/XalpHapVgb/dcDp4e+nAzdG2k8Ls37eBPw+Mj0kIp2gHQu6RkZg5crqHwAl00Pf/W7wlI98pPi0QtCvdjkJpJLnb2bXAscAC4AngC8A/wpcDywCJoH3u/sOMzPgEoLsoJ3AGe5eNYFfef4iPaqwR8DkZPzxcH+Aq6+G004rP7xnjwJ+kkp5/lrkJSKdIWFx1rUfuoUPXnp02ekK+tVpMxcR6XwlU03fHfjf2M5nygL/7t2a3kmDgr+IZKd0hS9wxec2Yb6HM6cvKDq1EPRnKWqlQm+jSF50wJaIZf2JrPD9zuQ7sOUjZTdyX3xRQb8VtI2jSB5kvCVirHCF72Ws5OyYKi8vvABzFKFaRp+lInmQdrmGFL5FfGVyGYaXBf5d9OGuwN9qCv4ieZBmuYYmC7JddFFws/Y8vlzU/jx9OMZLBl5Wf5+kbgr+InmQZrmGBguyXXJJEPQ/9ani9p3sg2P08UL9fZGGKfiL5EGa5RoqFWSLmUb61reCoP+xjxW3/5F5OMY+PFd8YEdpgWBpBQV/kTyoVq6hljn8wjmVFoZOTu59/pVXBi+1cmXxKU8/HVzipYML4q+R8gbtksDdu+JxxBFHuIi0wNq17v39hT1Ogkd/f9Be6ZyEx1o+GHvoqacaeF1pCjDuCTFVI3+RvKslEyjunBLf5/0YznKKvzXs2BFE9pe/vOQJ7SgeJ4lU20ck72bNip/KMQsK6FQ6B7iB93IyN5S1b2cBA749zZ5KnVTbR0SS1ZIJFHPOlZyO4WWB/wleiWMMDM5Ls5eSMgV/kbyrJRMocs41nILhnMGVRU/Zxn44xiuZSn/jF0mdgr9I3pXOvQ8MwD77BAu3Cpk/IyNc86GfYDgjXFP09E0M4i/pY7+BFzV330UU/EUkCNSbNsHVV8Ozz8L09N7Vuz848ybMYOTStxQ95bevPga3WQwOWrC91vbt2jaxiyj4i3SrRuvrVHpeJKtnHX+N4bxvV/F1778/+FxYsvU/FOy7WMuDv5ltMrP7zWyDmY2HbfPN7FYzezj8uW+r+yHSVq0unxxXX2fFiuqvU+15mzfzb/wVhrOUdUVP/dWvgqccdli6/xTJRstTPc1sEzDsPpPzZWZfBXa4+5fN7DxgX3f/TKXrKNVTukbCdoSpzoMPDcXveRvud9vI826+fBMnnlh+6B6GGR7cXvm60pE6MdVzKXBV+PtVwLsz6odI+tIunxyn0SqdMcdv41hssjzw/4yjcYzh/geVudOD2hH8HfiJmd1rZuHuEbzK3beFv/838Kq4J5rZCjMbN7PxqampNnRVJAVJAbhQ9yaNqaB6q3TG1OW5g7diOMdxW9Gp//7Z9fjgEEfbz5W508uS6j6k9QAOCH++Evg18DbgqZJzflftOqrtI11jcDC+7o1ZenVs6qmLU3Luz3lTbPduvrmpf7V0ILKs7ePuW8OfTwI/BI4EnjCz/QHCn0+2uh8ibRO3aMqsvDzCzp2wfHlj3wIKufkDAzNt++wTf244DfULjsRw3sydRYfXfeo/cIfjj6+vC9LdWhr8zeylZvYnhd+BdwEbgXXA6eFppwM3trIfIm0VV7CsUmJFXKZOrdlCzz478/v0dGzGzy8nBzCcN/GLovYb+Fvc4a+/dkxd/zzpEUlfCdJ4AK8hmOr5NfAAsCpsHwBuAx4G1gPzq11L0z7S1ZKmgqKPwcHg3LgpHTP3s86q7Zrhde67L/7wGKcUv14z1q4NrmMW/FQ55o5ChWmfls/5p/VQ8JeuVks9fLPg3Er3DKLBtfQeQvj4NX8a+/Rv83czf6RRN1/1+DtepeCvFb4i7RCdCkpSyNSptk1iwo5aD3IwhvNn3FfU/k0+ir/jOD48uD7d2jvtSGmVlpmTdQdEetrYWBAMN28OgnshXz5uEVjh2KJF8QuxYOb+QOS5D/M6Xs/DZad+ic/zef5P8Me/W1C3J82UzUbXGkhH0MhfpFWSSilA5R2sRkeD9jizZ+8N/I+yGMPLAv9nGcWxmcAPiZurN6XetQbSURT8RVql0rRItIomlJVPZuXK+A+A3bt5nAMxnNfyaNGhT34SfHCIUT4X35+0R+S17AMgHUvBX6RVqk2LVCqydumlwQdDJI9/G/thOIt4vOhyZ7AGHxziwgup/K0h7RG59uDtagr+Iq1SbVqk2g3TMIg+wSsxnFezrejUD3AdjrGm/2PFo+3S0XihrRUj8sI3GJV27joK/iKtMDYGf/xjeXs0CFf5ZrD98h9g09vZjyeKDr+f7+MY19kHi0fbhW8SzzxTfL2BAY3IpYyyfUTSFlfSGYIgfPHFM0F4/vxgVW6JHQf8KQMGcHJR+99wIzcWCuDGlW6O+yYBMG+eAr+UUfAXSVstQXhsDH7/+6LDT/Fy9uUp2FL8tKP5GT/jbcWNcVM4Sr2UOmjaRyRttQThVavgxRcB+APzMDwI/BEHz5nAsfLAPzAQP5JX6qXUQcFfJG1JwXb+/JlibZOTPEM/hvMy/lB02kKexB0evPIX8amUF18cf32lXkodFPxF0hYXhPv64OmnYXKS57wPw5nHM2VPdYwnC3sb1ZtKqdRLqUPL9/BNi/bwla5SWtbhj39k1/TTzGVX7OlOJDd/YAC2b489T6QenbiHr0hvi+S/v/DwJmx6e2zgd6w48Pf1JU/riKRIwV+kRXbvDmZf+vrKj+0N+gMDxdM0a9ZomkbaQsFfpFStu2gl2LMniOVzYhKpi0b6hZu3hRWyo6PBVFEaG7yLVKHgLxJVqd5OFe5B0J89O/6Yrx1LvhnbxOuKNCKz4G9mJ5jZQ2Y2YWbnZdUPkSINbFBSCPqzYv5vcpuFDw7NVOtMqoPTio1RmvwGI70tk+BvZrOBbwInAocAp5jZIVn0RaRIHatkKwb9/pcG0zvRUfzZZycH47RX5+qbhFSR1cj/SGDC3R91913AdcDSjPoieRcdIcdFcihbuJUY9D2oqR87ir/88uRgnPbqXG2xKFVkFfwPgKKi5FvCtiJmtsLMxs1sfGpqqm2dkxwpHSHv3l1+TmSVrFl8ufzCDuZA5T14o6LBOO3VuarzI1V09A1fd1/t7sPuPrxw4cKsuyPdqNq8d1IRttmzi27M2vKR6kG/oJ7ReiEYp706V3V+pIqsgv9W4KDI3weGbSLpqWXeO2kkvGcP7NmDTW7ClpcHYB8cCrJ34sSN4tu1u1alPqjOj0S5e9sfBKWkHwUWA33Ar4FDKz3niCOOcJG6DA4WBubFj8HBqufEPS34vyXyR3+/+9q18a+9dm1wbbPg51lnBecnPX/t2srHG1Hah2auJV0JGPekOJx0oNUP4CTgt8AjwKpq5yv4S93M4iO42cw5a9e69/VVD/pJHySFD5NaAmulYFzLB5VInSoFfxV2k941NBRM9ZQq3QVrwQJsOr6Q2t7/PWbNipncj+jvb26OPun6ZsEUlEgDVNhN8qmGeW8zYgO/Y7hF/veoNjffbBqlbtBKmyn4S+drdKVqIYNmYGCmbZ99gAopm9HaO9HAG/dBUqqZNErdoJU2U/CXzpbGStVnn937q01vj8/eKazILSgNvNFUzCTNjNK1EYu0mYK/dLZaVqpW+mYQPt/CMX2pwp3V2MALxdeF4F7B2rWtGaVXqv0jkrakO8Gd9lC2T05Vy9ipkiKZmL1jVjn7plrqpdIopQvQiame9T4U/HtQUgCNts+eXTkFstE8fbOiFM+y4D4wUPl1RbpApeCvaR/JRtJc/tln11Vrp/Qma+L0Tul2ie6wq2RbxcJ00tgYTE/H9zvppq7KJ0uXUfCXbCTN5a9eXVOtnb3z4eFN1sSgv3YM75tbe78mJ+H005OPx93UVflk6UJa5CXZqLZoqlTCYqekkjm+Ntw8JWmhV6XXqdSvtWvLb8TWuphMpM20yEs6T1JaZNweiDHnJ+bpFwquFQJ0vbn3lQL/wEB8Bo7KJ0sXUvCXbCQtalqxomIaZcXFWf0vDc6LBui0VsgWNluPo9W50oUU/CUbSYuaLr00tj2xnn70Rm5ciYVaVuZCcE50JXDU7NmVF1xpda50o6Q0oE57KNUzJ0rSPyvm6Ver2JlwTV+7Nrmt0bLKyvuXDkSFVM85WX/4iOxVyJoJV+QScw9175T80KL4m6xxUy0jI8Wj9rGx4BvC5s3B+aVTRR//+EyqZ1gLqKrS1xDpcJr2kc6xahW285nkPP3BoZn0yUanWmpJy4zUAmJ6Wmmb0pOU6ikdITFlk5IDfX2wZk0wyq42go9TLS1TaZvSQyqleir4S6ZqDvpRAwOwPX7zlaqqbZqiTVWkh2SS529m/2BmW81sQ/g4KXLsfDObMLOHzOz4VvVBOldiyqbNqhz4Ibn0Qi2qpWUqbVNyotVz/he5++Hh4yYAMzsEWAYcCpwAXGpmCSt7pNdUDPqDQ3DssclfB9JQ7V6B0jYlJ7K44bsUuM7dn3f3x4AJ4MgM+iH1aLJwWWLQL2yiUrj5euedsHJl5U1TkvLxa1Ft0xRtqiI50ergf46Z3Wdma8xs37DtAODxyDlbwrYyZrbCzMbNbHxqaqrFXZVETRQuSwz6HpRiiC3udtNNM5umvOQl5U9+//sb+mcwNgYLFsDy5cG/Yf78+JvE2lRFcqCp4G9m681sY8xjKXAZ8FrgcGAb8LV6r+/uq9192N2HFy5c2ExXpRm17KZVomLQL9xPrVYTZ2QEPvzh8gtddVX9qZdjY3DGGcX3C6an4cwzlcYpudRU8Hf349z9sJjHje7+hLvvdvc9wLeZmdrZChwUucyBYZt0qjoKl1UtuBaVdBN11qyZ6aXrry/PvqnywRNr1Sp44YXy9l276r+WSA9oZbbP/pE/3wNsDH9fBywzs7lmthhYAtzdqn5ICmrIgKlYcA0LpllKR9lJdXd2756ZXqp3U5Uklc5X9U3JoVbO+X/VzO43s/uAtwOfBHD3B4Drgd8ANwMfdfeY7ZqkY1TIgEkM+gMLylM2d+0KSicUlN5cTSrnHKfe1MtK5yuNU3KoZbV93P3UCsdGAeXOdYvCDc/Ialqb3ATLy0/dO0NjCSP2Sjn6cVs2xmkk9XJ0NJjzL5366etTGqfkkmr7SG3CDBjzPUHgL1F0I7dWpVlElQwMNJd6OTIC3/1ucZrowMBMqQiRnFFVT6lJYhmGpJg9MBA/yo8G37gsoiTz5jVe0qFAlTdF9tLIXyqqKWWzILoQDGZ+Rk1PzywSq+dGq27KiqRKwV9i1RX0oXwKZ3oa5syZGelHL1ZYJDZ/fu0d0k1ZkVQp+EuRuoN+QdwUzq5dwXTN4GB8rj6UZxH19ZWv6lVtHZHUKfgLEB/05zM9k6e/YEHllbCVFoIlHduxo7yOzpo1wY1Z1dYRaSnV88+5uFH+PP7AH3hZ+YH+/uRAXGkTFNAGKSIZyKSev3S2uJH+3LlBaeXYwA+VyypUKoWsMskiHUfBP2figr6FFZWfe47qN1aTpnAqlUJWmWSRjqNpn5yoOU+/kLWTlH+vqRqRrqFpnxyrO3unMEqP2zDFDE46qbxdRLqOgn+PajhlE4IPgO3b4ayzii/i3lgtfRHpOAr+PWbffZsI+qVuuimdWvoi0nEU/HvE0FAQ9J96qri9oaBfUMcmLiLSXRT8u9zJJwdBP5pGv//+TQb9gho2cRGR7qTg36U+8IEg6N9ww0zboYcGAf+//iulFxkdDcotRKn+vUhPUPDvMiMjQdC//vqZtpNOCoL+xo3Jz2tY6deHLkkNFpHKmgr+ZvY+M3vAzPaY2XDJsfPNbMLMHjKz4yPtJ4RtE2Z2XjOvnyennRYE/WuumWl717uCWPyjH0VOjJZVLpROblTcpucvvKAbviI9oNnNXDYC7wW+FW00s0OAZcChwKuB9Wb2+vDwN4F3AluAe8xsnbv/psl+9KwzzwzqnEW94x2wfn3MyaULtAqlk6Gx1bS64SvSs5oa+bv7g+7+UMyhpcB17v68uz8GTABHho8Jd3/U3XcB14XnSomPfCQY6UcD/zHHBCP92MAP8WWVm0nN1A1fkZ7Vqjn/A4DHI39vCduS2mOZ2QozGzez8ampqZZ0tNMU1lVdccVM29FHB0H/9turPDntkboKson0rKrB38zWm9nGmEfLR+zuvtrdh919eOHCha1+uUydc04Q9C+/fKbtqKOCoP+zn9V4kbRH6irIJtKzqs75u/txDVx3K3BQ5O8DwzYqtOfSJz4BF19c3DY8DPfc08DFRkfLi7I1O1LXpuciPalV0z7rgGVmNtfMFgNLgLuBe4AlZrbYzPoIbgqva1EfOtqnPx0MpqOB/41vDEb6DQV+0EhdRGrWVLaPmb0H+AawEPiRmW1w9+Pd/QEzux74DfAi8FF33x0+5xzgFmA2sMbdH2jqX9Blzj0XLriguO2ww+D++1N6AY3URaQGquffJuedB1/5SnHbwQfDgw9m0x8R6X2V6vk3m+cvVXzuc+VT7q99LUxMZNMfERFQeYeW+cIXgmn3aOAfGgrm9FMP/Gmu6hWRXNDIP2Vf+lIQ+KMOOqiFi2LTXtUrIrmgkX9KRkeDkX408O+3XzDSb2k1hLRX9YpILmjk36QvfxnOP7+4bWAg2AWxLVR/R0QaoJF/gy64IBjpRwP/K14RjPTbFvhB9XdEpCEK/nW66KIg6J977kzbvHlB0P/d7zLokOrviEgDNO1To5tugr/8y+K2uXPhueey6c9ehZu6q1YFUz2LFgWBXzd7RaQCBf8q7rwT3vzm4rZZs2D37mz6E0urekWkTpr2STAxEUzvRAP/yScH0zsdFfhFRBqg4F/ikUeCoL9kyUzb6GgQ9P/lX7Lrl4hImjTtE3r00aDsQtQ118App2TTHxGRVsp98H/sMXjNa4rbxsbggx/Mpj8iIu2Q2+C/aRMsXlzcdvXVsHx5Jt0REWmr3AX/ycmg9lnUVVfBaadl0h0RkUzk5obv5s0we3Zx4L/yyuBGrgK/iORNzwf/zZthzpxgR8M9e4K2NWuCoH/66dn2TUQkK00FfzN7n5k9YGZ7zGw40j5kZs+a2YbwcXnk2BFmdr+ZTZjZ183MmulDNYODM3n53/lOEPTPOKOVrygi0vmanfPfCLwX+FbMsUfc/fCY9suAjwC/AG4CTgB+3GQ/Et1+ezD619SOiMiMpoK/uz8IUOvg3cz2B17m7neFf38PeDctDP7HHNOqK4uIdK9WzvkvNrNfmdlPzeytYdsBwJbIOVvCtlhmtsLMxs1sfGpqqoVdFRHJl6ojfzNbD+wXc2iVu9+Y8LRtwCJ3nzazI4B/NbND6+2cu68GVgMMDw97vc8XEZF4VYO/ux9X70Xd/Xng+fD3e83sEeD1wFbgwMipB4ZtIiLSRi2Z9jGzhWY2O/z9NcAS4FF33wY8bWZvCrN8TgOSvj2IiEiLNJvq+R4z2wL8OfAjM7slPPQ24D4z2wD8AFjp7jvCY2cDVwATwCO08GaviIjEM/fumEofHh728fHxrLshItI1zOxedx+OO9bzK3xFRKScgr+ISA4p+IuI5JCCv4hIDin4i4jkkIK/iEgOKfiLiOSQgr+ISA4p+FcyNhbs+zhrVvBzbCzrHomIpCJ3G7jXbGwMVqyAnTuDvycng78BRkay65eISAo08k+yatVM4C/YuTNoFxHpcgr+STZvrq9dRKSLKPgnWbSovnYRkS7S28G/mRu2o6PQ31/c1t8ftIuIdLneDf6FG7aTk+A+c8O21g+AkRFYvRoGB8Es+Ll6tW72ikhP6N16/kNDQcAvNTgImzal1S0RkY6Vz3r+umErIpKo2W0cLzCz/2dm95nZD83sFZFj55vZhJk9ZGbHR9pPCNsmzOy8Zl6/orRv2GrBl4j0kGZH/rcCh7n7G4DfAucDmNkhwDLgUOAE4FIzmx1u6v5N4ETgEOCU8Nz0pXnDttn7ByIiHaap4O/uP3H3F8M/7wIODH9fClzn7s+7+2MEm7UfGT4m3P1Rd98FXBeem740b9hqwZeI9Jg0yzucCXw//P0Agg+Dgi1hG8DjJe1HJV3QzFYAKwAWNTJdMzKSTnaO7h+ISI+pOvI3s/VmtjHmsTRyzirgRSDVeRB3X+3uw+4+vHDhwjQvXR8t+BKRHlN15O/ux1U6bmYfAv4KeIfP5I1uBQ6KnHZg2EaF9s41Olpc5A204EtEulqz2T4nAOcCf+Pu0UnxdcAyM5trZouBJcDdwD3AEjNbbGZ9BDeF1zXTh7bQgi8R6THNzvlfAswFbjUzgLvcfaW7P2Bm1wO/IZgO+qi77wYws3OAW4DZwBp3f6DJPrRHWvcPREQ6QO+u8BURybl8rvAVEZFECv4iIjmk4C8ikkMK/iIiOdQ1N3zNbAqIqdGciQXA9qw70UH0fhTT+1FM70exdr4fg+4eu0K2a4J/JzGz8aQ76Hmk96OY3o9iej+Kdcr7oWkfEZEcUvAXEckhBf/GrM66A4FT8JEAAAHtSURBVB1G70cxvR/F9H4U64j3Q3P+IiI5pJG/iEgOKfiLiOSQgn+DKm1en0dm9j4ze8DM9phZ5mlsWTCzE8zsITObMLPzsu5P1sxsjZk9aWYbs+5L1szsIDO73cx+E/5/8vGs+6Tg37jYzetzbCPwXuCOrDuSBTObDXwTOBE4BDjFzA7JtleZuxI4IetOdIgXgU+7+yHAm4CPZv3fh4J/gypsXp9L7v6guz+UdT8ydCQw4e6Puvsu4DpgaZXn9DR3vwPYkXU/OoG7b3P3X4a//wF4kJl9zTOh4J+OM4EfZ90JydQBwOORv7eQ8f/c0pnMbAh4I/CLLPvR7E5ePc3M1gP7xRxa5e43hue0ZPP6TlTL+yEiycxsHnAD8Al3fzrLvij4V9Dg5vU9q9r7kXNbgYMifx8YtokAYGYvIQj8Y+7+f7Puj6Z9GlRh83rJp3uAJWa22Mz6gGXAuoz7JB3Cgk3OvwM86O4XZt0fUPBvxiXAnxBsXr/BzC7PukNZMrP3mNkW4M+BH5nZLVn3qZ3Cm//nALcQ3My73t0fyLZX2TKza4E7gf9hZlvM7O+y7lOG3gKcChwbxosNZnZSlh1SeQcRkRzSyF9EJIcU/EVEckjBX0QkhxT8RURySMFfRCSHFPxFRHJIwV9EJIf+P2ISt9+tJqhJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxtCobAVnyV5"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNdt53Yqmz1p",
        "outputId": "e2c59055-a2b2-44df-f003-b9e6c9988947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "#  Model\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "# Loss and optimizer\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 10, loss = 0.6984\n",
            "epoch: 20, loss = 0.5535\n",
            "epoch: 30, loss = 0.4676\n",
            "epoch: 40, loss = 0.4112\n",
            "epoch: 50, loss = 0.3712\n",
            "epoch: 60, loss = 0.3409\n",
            "epoch: 70, loss = 0.3170\n",
            "epoch: 80, loss = 0.2976\n",
            "epoch: 90, loss = 0.2813\n",
            "epoch: 100, loss = 0.2675\n",
            "accuracy: 0.8947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x475BDXNper"
      },
      "source": [
        "Dataset and DataLoader - Batch Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ljzdc3kS7Ub",
        "outputId": "a07d2583-6c42-46e0-f5c6-1a7fb4134dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!git clone https://github.com/shaheer1995/pytorch_tutorials"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch_tutorials'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 6 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcufQUNZVM15"
      },
      "source": [
        "data_path = \"/content/pytorch_tutorials/data/wine/wine.csv\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUvwJWkBMhY3",
        "outputId": "a4cbeb7e-6f27-41c6-98ea-5b8b0dfd8d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "  def __init__(self):\n",
        "    xy = np.loadtxt(data_path,delimiter=\",\",dtype=np.float32,skiprows=1)\n",
        "    self.x = torch.from_numpy(xy[:,1:])\n",
        "    self.y = torch.from_numpy(xy[:,[0]])\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index],self.y[index]\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "dataloader = DataLoader(dataset=dataset,batch_size=4,shuffle=True,num_workers=2)\n",
        "\n",
        "# dataiter = iter(dataloader)\n",
        "# data = dataiter.next()\n",
        "# features,labels = data\n",
        "# print(features,labels)\n",
        "\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples,n_iterations)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(inputs, lables) in enumerate(dataloader):\n",
        "    if (i+1)%5 == 0:\n",
        "      print(f'epoch : {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178 45\n",
            "epoch : 1/2, step 5/45, inputs torch.Size([4, 13])\n",
            "epoch : 1/2, step 10/45, inputs torch.Size([4, 13])\n",
            "epoch : 1/2, step 15/45, inputs torch.Size([4, 13])\n",
            "epoch : 1/2, step 20/45, inputs torch.Size([4, 13])\n",
            "epoch : 1/2, step 25/45, inputs torch.Size([4, 13])\n",
            "epoch : 1/2, step 30/45, inputs torch.Size([4, 13])\n",
            "epoch : 1/2, step 35/45, inputs torch.Size([4, 13])\n",
            "epoch : 1/2, step 40/45, inputs torch.Size([4, 13])\n",
            "epoch : 1/2, step 45/45, inputs torch.Size([2, 13])\n",
            "epoch : 2/2, step 5/45, inputs torch.Size([4, 13])\n",
            "epoch : 2/2, step 10/45, inputs torch.Size([4, 13])\n",
            "epoch : 2/2, step 15/45, inputs torch.Size([4, 13])\n",
            "epoch : 2/2, step 20/45, inputs torch.Size([4, 13])\n",
            "epoch : 2/2, step 25/45, inputs torch.Size([4, 13])\n",
            "epoch : 2/2, step 30/45, inputs torch.Size([4, 13])\n",
            "epoch : 2/2, step 35/45, inputs torch.Size([4, 13])\n",
            "epoch : 2/2, step 40/45, inputs torch.Size([4, 13])\n",
            "epoch : 2/2, step 45/45, inputs torch.Size([2, 13])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C43tSNgN9zCP"
      },
      "source": [
        "Softmax and Cross entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0ZwdVhEkXk5",
        "outputId": "4af67b8f-49a3-436f-df1f-f7d9ffb97c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy : ', outputs)\n",
        "\n",
        "y = torch.tensor([2.0,1.0,0.1])\n",
        "output = torch.softmax(y,dim=0)\n",
        "print(output)\n",
        "\n",
        "def cross_entropy(actual,predicted):\n",
        "  loss = -np.sum(actual*np.log(predicted))\n",
        "  return loss\n",
        "\n",
        "Y = np.array([1,0,0])\n",
        "\n",
        "Y_pred_good = np.array([0.7,0.2,0.1])\n",
        "Y_pred_bad = np.array([0.1,0.3,0.6])\n",
        "\n",
        "l1 = cross_entropy(Y,Y_pred_good)\n",
        "l2 = cross_entropy(Y,Y_pred_bad)\n",
        "\n",
        "print(f'Loss 1 numpy : {l1:.3f}')\n",
        "print(f'Loss 2 numpy : {l2:.3f}')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "softmax numpy :  [0.65900114 0.24243297 0.09856589]\n",
            "tensor([0.6590, 0.2424, 0.0986])\n",
            "Loss 1 numpy : 0.357\n",
            "Loss 2 numpy : 2.303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M61rfiPaK2r",
        "outputId": "e932dbf3-924f-439d-d68d-a0914db11982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "Y = torch.tensor([2,0,1])\n",
        "\n",
        "Y_pred_good = torch.tensor([[0.0,1.0,2.1],[2.0,1.0,0.1],[0.0,3.0,0.1]])\n",
        "Y_pred_bad = torch.tensor([[2.5,2.0,0.3],[0.1 ,2.0,2.3],[0.1,3.0,0.1]])\n",
        "\n",
        "l1 = loss(Y_pred_good,Y)\n",
        "l2 = loss(Y_pred_bad,Y)\n",
        "\n",
        "print(f'Loss 1 numpy : {l1.item():.3f}')\n",
        "print(f'Loss 2 numpy : {l2.item():.3f}')\n",
        "\n",
        "_, prediction1 = torch.max(Y_pred_good,1)\n",
        "_, prediction2 = torch.max(Y_pred_bad,1)\n",
        "\n",
        "print(prediction1)\n",
        "print(prediction2)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss 1 numpy : 0.297\n",
            "Loss 2 numpy : 1.887\n",
            "tensor([2, 0, 1])\n",
            "tensor([0, 2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EBsrAlJ031v"
      },
      "source": [
        "Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdX8F91J01hQ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNet1(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size,hidden_size):\n",
        "    super(NeuralNet2,self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size,hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    y_pred = torch.sigmoid(out)\n",
        "    return y_pred\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size = 5)\n",
        "criterion = nn.BCELoss()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9loVAgU_1W6J"
      },
      "source": [
        "Multiclass Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2llYGHLb6c8"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNet2(nn.Module):\n",
        "\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet2,self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size,hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size,num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size = 5, num_classes = 3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}